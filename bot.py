import os
from flask import Flask, request, abort, jsonify
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    filters,
)
import google.generativeai as genai
import logging
from base_conhecimento.faq_data import faq_data  # Importa칞칚o ajustada para a pasta base_conhecimento

# --- Configura칞칚o de Logging (Mantenha este bloco no topo) ---
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
# --- Fim da Configura칞칚o de Logging ---

# --- Vari치veis de Ambiente ---
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

if not TELEGRAM_BOT_TOKEN:
    logger.critical("TELEGRAM_BOT_TOKEN n칚o encontrado nas vari치veis de ambiente! O bot n칚o pode iniciar.")
    # N칚o levante erro fatal aqui, deixe o try-except principal lidar com isso
if not GEMINI_API_KEY:
    logger.critical("GEMINI_API_KEY n칚o encontrado nas vari치veis de ambiente! A IA n칚o funcionar치.")

# Configura a API Gemini
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-pro')

# Dicion치rio para armazenar o hist칩rico de conversa do Gemini
conversations = {}

# --- Fun칞칫es do Bot ---

async def start(update: Update, context):
    user_id = update.effective_user.id
    user_name = update.effective_user.first_name
    logger.info(f"Comando /start recebido de {user_name} (ID: {user_id})")

    # Inicia uma nova conversa Gemini para o usu치rio
    conversations[user_id] = model.start_chat(history=[])

    welcome_message = (
        "Fala, mestre! 游꽄 Bem-vindo  Loja CHOPP! O gar칞om digital est치 aqui pra te ajudar. "
        "O que manda hoje?!\n\n"
        "游꽄 - Onde fica a loja?\n"
        "游 - Qual nosso hor치rio?\n"
        "游닆 - Quero ver o card치pio!\n"
        "游 - Tirar uma d칰vida com a IA!\n\n"
        "칄 s칩 pedir que eu trago a informa칞칚o geladinha!"
    )
    await update.message.reply_text(welcome_message)

async def handle_message(update: Update, context):
    user_text = update.message.text.lower()
    user_id = update.effective_user.id
    user_name = update.effective_user.first_name
    logger.info(f"Mensagem recebida de {user_name} (ID: {user_id}): {user_text}")

    # Verifica se o usu치rio quer usar a IA
    if "tirar uma d칰vida com a ia" in user_text:
        await update.message.reply_text(
            "Certo! Estou ativando minha mente para suas perguntas. Pode mandar sua d칰vida para a IA!"
        )
        context.user_data['using_ai'] = True
        return

    # Se o usu치rio est치 no modo IA
    if context.user_data.get('using_ai', False):
        await send_to_gemini(update, context)
        return

    # L칩gica de FAQ
    matched_faqs = []
    for item in faq_data:
        if any(keyword in user_text for keyword in item["palavras_chave"]):
            matched_faqs.append(item)

    if not matched_faqs:
        await update.message.reply_text("Desculpe, n칚o entendi. Posso te ajudar com o card치pio, hor치rios ou localiza칞칚o?")
        logger.info(f"Nenhuma FAQ encontrada para: {user_text}")
    elif len(matched_faqs) == 1:
        await update.message.reply_text(matched_faqs[0]["resposta"])
        logger.info(f"Resposta direta da FAQ: {matched_faqs[0]['pergunta']}")
    else:
        keyboard = []
        for faq in matched_faqs:
            # Use 'pergunta' como texto do bot칚o e 'id' como callback_data
            keyboard.append([InlineKeyboardButton(faq["pergunta"], callback_data=str(faq["id"]))])
        reply_markup = InlineKeyboardMarkup(keyboard)
        await update.message.reply_text(
            "Encontrei algumas op칞칫es. Qual delas voc칡 gostaria de saber?", reply_markup=reply_markup
        )
        logger.info(f"M칰ltiplas FAQs encontradas. Oferecendo bot칫es para: {[f['pergunta'] for f in matched_faqs]}")

async def button_callback_handler(update: Update, context):
    query = update.callback_query
    await query.answer()
    selected_faq_id = query.data
    user_name = update.effective_user.first_name
    logger.info(f"Bot칚o de FAQ pressionado por {user_name}: ID {selected_faq_id}")

    for item in faq_data:
        if str(item["id"]) == selected_faq_id:
            await query.edit_message_text(text=item["resposta"])
            logger.info(f"Resposta da FAQ por bot칚o: {item['pergunta']}")
            return
    logger.warning(f"ID de FAQ n칚o encontrado para callback_data: {selected_faq_id}")
    await query.edit_message_text(text="Desculpe, n칚o consegui encontrar a informa칞칚o para essa op칞칚o.")


async def send_to_gemini(update: Update, context):
    user_id = update.effective_user.id
    user_message = update.message.text
    user_name = update.effective_user.first_name
    logger.info(f"Enviando para Gemini de {user_name} (ID: {user_id}): {user_message}")

    if user_id not in conversations:
        logger.info(f"Iniciando nova conversa Gemini para o usu치rio {user_id}")
        conversations[user_id] = model.start_chat(history=[])

    try:
        response = await conversations[user_id].send_message_async(user_message)
        gemini_response_text = response.text
        logger.info(f"Resposta do Gemini para {user_id}: {gemini_response_text}")
        await update.message.reply_text(gemini_response_text)
    except Exception as e:
        logger.error(f"Erro ao comunicar com a API Gemini para o usu치rio {user_id}: {e}", exc_info=True)
        await update.message.reply_text("Desculpe, n칚o consegui processar sua pergunta com a IA no momento.")
    finally:
        # Desativa o modo IA ap칩s a resposta do Gemini ou erro
        context.user_data['using_ai'] = False
        logger.info(
